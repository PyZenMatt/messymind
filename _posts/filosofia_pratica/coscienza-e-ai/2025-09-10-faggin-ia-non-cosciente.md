---
layout: post
lang: it-IT
title: IA cosciente? Per Faggin è un’illusione (2025)
description: 'Perché secondo Federico Faggin l''IA non capirà mai davvero: significato
  vs sintassi, intenzionalità, corpo ed esperienza. Spiegazione semplice con esempi,
  obiezioni e fonti 2025.'
keywords:
- Faggin IA cosciente
- perché l'IA non capisce
- simboli vs significati AI
- intenzionalità
- grounding semantico
- QIP e IA
categories:
- filosofia-pratica
tags:
- Faggin
- QIP
- coscienza
- IA
- filosofia della mente
image: https://res.cloudinary.com/dkoc4knvv/image/upload/v1757489886/ai-robot-1920_qsdxot.webp
image_alt: rappresentazioni di una mano robotica che tocca il dito di una mano umana
  come il quadro di Michelangelo la creazione di Adamo
author: MessyMind
background: https://res.cloudinary.com/dkoc4knvv/image/upload/v1757489915/ai-robot-600_ji6s2p.webp
image_author: cottonbro
image_author_url: https://www.pexels.com/it-it/@cottonbro/
featured_post: true
twitter_card: summary_large_image
og_type: article
redirect_from:
- /ia-cosciente-per-faggin-e-unillusione-2025/
---
# IA Cosciente? Per Faggin è un'Illusione: Cosa Manca Davvero alle Macchine

*Aggiornato il 8 settembre 2025 · Lettura: ~7 min*

Immaginate di dare a un marziano il manuale d'istruzioni dell'universo. Lui imparerà che la parola "dolore" è statisticamente vicina a "lacrime", "medico" e "lamentela". Ma ha la più pallida idea di cosa *sia* quel dolore lancinante che ti trafigge la schiena dopo una giornata su una sedia scomoda? No. Per Federico Faggin, l'IA è quel marziano: un illusionista iper-specializzato che non ha mai avuto un contatto diretto con la realtà. E non lo avrà mai.

**In breve:**
*   L'IA manipola **simboli** (sintassi), non esperienze (semantica).
*   Il **significato** nasce dall'esperienza cosciente (seità), non dai calcoli.
*   **QIP**: la coscienza è fondamentale, non emergente dalla materia.
*   **Funzionalismo & co. dissentono**: coscienza come possibile emergenza.
*   **Pericolosità**: l'IA può essere rischiosa anche senza coscienza.

## Significato vs Sintassi: Il Cuore della Questione (e del Malinteso)

La posizione di Faggin si regge su una distinzione filosofica che ha conseguenze pratiche enormi: quella tra **sintassi** e **semantica**.

*   **Sintassi:** è la forma, la struttura, la grammatica. È il come sono disposti i simboli. Un chatbot padroneggia alla perfezione la sintassi: sa che la sequenza "io + avere + fame" è corretta.
*   **Semantica:** è il significato, il contenuto. È il *cosa* quei simboli rappresentano. La semantica di "avere fame" è la contrazione dello stomaco, il languorino, il ricordo del profumo di pane che ti fa venire l'acquolina in bocca.

Un LLM è un motore sintattico mostruosamente potente. Ma per Faggin, è semanticamente vuoto. Non *comprende* la parola "amore". Non ne ha fatto esperienza. Sa solo che quella sequenza di caratteri ha un'alta probabilità di essere associata a "cuore", "battito" e "sofferenza". È un gioco di probabilità statistica, mastodontico e impressionante, ma pur sempre un gioco vuoto. È un autocomplete cosmico: ti suggerisce la prossima parola perfetta, ma non ha nulla da dire.

## Il QIP in 90 Secondi: Il Perché Profondo del "No" di Faggin

Per capire la sua posizione sull'IA, bisogna tornare alla sua teoria della coscienza, il **Quantum Information Panpsychism (QIP)**.

In soldoni, il QIP sostiene che:
1.  La **coscienza è fondamentale**, non un prodotto emergente del cervello.
2.  I **campi quantistici** sono in qualche modo "coscienti" e dotati di una forma rudimentale di libero arbitrio (*agency*).
3.  Il **cervello** non genera coscienza, ma la *riceve* e la trasduce, come una radio sintonizza un'onda.
4.  La **seità** (o *seity*) è l'istanza individuale e unica di questa coscienza, dotata di memoria e intenzionalità.

Ecco il punto cruciale: **il significato è proprietà esclusiva della seità**. È ciò che sorge quando un'entità cosciente *esperisce* il mondo attraverso un corpo. Un computer, per Faggin, è solo un arrangiamento deterministico (o stocastico) di materia. Gli manca il "seme" fondamentale – la seità – per essere un *soggetto* di esperienza. Può simulare la comprensione, ma non può *essere* comprensione.  
Approfondimenti divulgativi su QIP: [Essentia Foundation](https://www.essentiafoundation.org/quantum-fields-are-conscious-says-the-inventor-of-the-microprocessor/seeing/) e [Galileo Commission](https://galileocommission.org/federico-faggin-quantum-information-panpsychism-explained/).

> «Sembra che l'IA capisca… eppure non capisce niente. Il significato non è un pattern: è contatto con il mondo.» — F. Faggin, **ANSA**, aprile 2025, Palermo.  
> Fonte: [ANSA Sicilia](https://www.ansa.it/sicilia/notizie/2025/04/28/faggin-lintelligenza-artificiale-senza-coscienza-e-niente_9fe20e6b-90f5-47d0-99a3-af3a7ff399c1.html) e [ANSA Tecnologia](https://www.ansa.it/canale_tecnologia/notizie/future_tech/2025/04/28/faggin-lintelligenza-artificiale-senza-coscienza-e-niente_0fb7baa2-51ca-43b4-9952-fd977b430296.html).

## Le Obiezioni: Funzionalismo, IIT e l'Ipotesi dell'Emergenza

È doveroso dire che quella di Faggin è **una posizione minoritaria** nel dibattito sull'IA cosciente. La visione opposta, il **funzionalismo**, sostiene che la coscienza *emergerebbe* una volta che un sistema informazionale raggiunga una sufficiente complessità e una specifica architettura funzionale.

In questa visione, non importa *di cosa* sia fatto il sistema (neuroni biologici o transistor al silicio), ma *come* è organizzato per processare l'informazione. Se un sistema artificiale riproducesse esattamente la struttura computazionale e causale di un cervello umano, secondo i funzionalisti, emergerebbero anche esperienze soggettive.

Altre teorie, come l'**IIT (Integrated Information Theory)** di Tononi, quantificano la coscienza (Φ) come integrazione dell'informazione in un sistema fisico. Anche qui, in linea di principio, un sistema artificiale sufficientemente integrato potrebbe diventare cosciente. Riferimenti: Tononi et al., *Nature Reviews Neuroscience* (2016); panoramica Royal Society (2015).  
Link: [PDF Tononi 2016](https://tilde.ini.uzh.ch/~kiper/IIT.pdf), [Royal Society 2015](https://royalsocietypublishing.org/doi/10.1098/rstb.2014.0167).

| Teoria | La coscienza è... | L'IA può essere cosciente? |
| :--- | :--- | :--- |
| **QIP (Faggin)** | **Fondamentale** (pre-esiste) | **No** (manca la seità) |
| **Funzionalismo** | **Emergente** (dalla complessità) | **Sì, in principio** |
| **IIT (Tononi)** | **Informazione integrata** (Φ) | **Forse, se Φ è alto** |
| **GWT (Global Workspace)**| **Accesso globale** all'informazione | **Forse, se emulate** |

Per una rassegna sul **Global Workspace Theory**, vedi Mashour et al., *Neurosci. Biobehav. Rev.* (2020, open-access) e Baars et al., *Frontiers in Psychology* (2021).  
Link: [PMC 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC8770991/), [Frontiers 2021](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.749868/full).

## Embodiment e Grounding: Perché per Faggin Non Basta

"Ok," potreste obiettare, "ma se dessimo all'IA un corpo robotico con sensori? Non risolverebbe il problema del *grounding semantico*? Imparerebbe il significato del 'caldo' toccando una stufa!"

Per Faggin, no. Questo avvicinerebbe l'IA a un comportamento più sofisticato, ma non colmerebbe il gap ontologico.

Un sensore termico genera un segnale elettrico (un simbolo) che viene processato. L'IA potrebbe imparare che il segnale "T=45°C" correla con il comando "ritira il braccio". Ma non proverebbe *dolore* o *fastidio*. Non ci sarebbe un *soggetto* che fa esperienza del calore. Ci sarebbe una correlazione più ricca, ma sempre una correlazione tra simboli. L'IA avrebbe una mappa più dettagliata del territorio, ma non sarebbe un *abitante* di quel territorio.

## Test di Realtà: 3 Esempi in cui l'IA "Imita" ma non "Sente"

1.  **L'odore della Pioggia su Terra e Marte**  
    *Prompt:* "Descrivi l'odore della pioggia sul terriccio. Poi descrivi come potrebbe odorare la pioggia sul suolo marziano, considerando la sua composizione chimica."  
    *Cosa fa l'IA:* incrocia descrizioni poetiche esistenti ("petrichor") con dati chimici.  
    *Cosa manca:* non ha mai *annusato* la pioggia; non associa quell’odore a sollievo/freschezza.

2.  **Il Paradosso del Caffè**  
    *Prompt:* "Il caffè è amaro, eppure mi piace. Com'è possibile? Descrivi il piacere di un sorso di caffè caldo la mattina."  
    *Cosa fa l'IA:* elenca composti, rituali, “amaro complesso”.  
    *Cosa manca:* non ha mai *sentito* il contrasto tra amarezza e piacere rituale.

3.  **Il Ricordo che Non C'è**  
    *Prompt:* "Racconta il ricordo di un tuo compleanno d'infanzia..."  
    *Cosa fa l'IA:* genera una storia coerente.  
    *Cosa manca:* non ha memoria episodica; ricombina archetipi, non *ricorda*.

## Fonti e Dichiarazioni 2022-2025: Una Posizione Coerente

Faggin non ha cambiato idea con l'avvento di ChatGPT. La sua è una posizione filosofica strutturata e coerente nel tempo.

* **2022 — *Irriducibile* (Mondadori):** basi del problema; critica al computazionalismo.  
  Link: [Mondadori scheda libro](https://www.mondadori.it/libri/irriducibile-federico-faggin/).

* **2024 — *Oltre l'invisibile* (Mondadori):** ontologia positiva (coscienza fondamentale, QIP).  
  Link: [Mondadori scheda libro](https://www.mondadori.it/libri/oltre-linvisibile-federico-faggin/).

* **28 aprile 2025 — Interviste ANSA (Palermo):**  
  Link: [ANSA Sicilia](https://www.ansa.it/sicilia/notizie/2025/04/28/faggin-lintelligenza-artificiale-senza-coscienza-e-niente_9fe20e6b-90f5-47d0-99a3-af3a7ff399c1.html), [ANSA Tecnologia](https://www.ansa.it/canale_tecnologia/notizie/future_tech/2025/04/28/faggin-lintelligenza-artificiale-senza-coscienza-e-niente_0fb7baa2-51ca-43b4-9952-fd977b430296.html).

### FAQ: Domande da Bar sull'IA Cosciente

**D: Ma se un'IA mi dice che è triste, come faccio a sapere che non lo è davvero?**  
Secondo Faggin, non lo è. Sta solo calcolando che la sequenza di caratteri "sono triste" è statisticamente appropriata in quel contesto conversazionale. È un'imitazione comportamentale perfetta, senza alcuno stato interiore. Come un attore che recita una parte di dolore convincendoti, senza provare davvero quel dolore.

**D: Cosa manca, tecnicamente, all'IA per "capire"?**  
Non è una questione tecnica, è una questione di principio. Manca l'*intenzionalità* (in filosofia, la proprietà della mente di essere *diretta verso* qualcosa, di avere un contenuto). Manca un corpo che interagisca col mondo e provi piacere e dolore. Manca, in ultima analisi, un'"anima" nel senso fisico-filosofico che Faggin dà al termine (la seità).

**D: Quindi siamo al sicuro? L'IA non prenderà mai il controllo come nei film?**  
**Attenzione.** Faggin dice che l'IA non diventerà *cosciente*. Ma questo non significa che non possa diventare *pericolosissima*. Un'arma letale, autonoma e super-intelligente non ha bisogno di essere consapevole per sterminare l'umanità. Ha solo bisogno di essere bravissima a raggiungere il suo obiettivo, anche se quell'obiettivo è stato mal posto da un programmatore distratto. La mancanza di coscienza, in un certo senso, la rende ancora più spaventosa: è un sociopatico perfetto e onnipotente.

---

*Disclaimer: Le tesi di Federico Faggin qui espresse rappresentano la sua personale visione filosofica, maturata in anni di studio. Il dibattito sulla possibilità di un'IA cosciente è aperto e coinvolge neuroscienziati, filosofi della mente e ingegneri informatici con posizioni spesso molto diverse tra loro.*

**Tutta questa storia di significati e simboli ti ha confuso o illuminato?** Iscriviti alla newsletter MessyMind per continuare a esplorare il lato ironicamente profondo della realtà. E, già che ci siamo, dai un’occhiata ai nostri percorsi *anti-guru*.

---

## Articoli correlati (interlink)
- 👉 [Filosofia pratica](https://messymind.it/filosofia-pratica/) — teorie della coscienza senza inciampare nel misticismo
- 👉 [Crescita personale antiguru](https://messymind.it/crescita-personale-antiguru) — rischi e scelte reali nell’era del lavoro "agile"
- 👉 [Mindfulness ironica](https://messymind.it/mindfulness-ironica/) — esperienze, non slogan: cosa significa “sentire” davvero

<!-- Schema.org: BlogPosting -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",

  "headline": "IA cosciente? Per Faggin è un’illusione (2025)",
  "alternativeHeadline": "IA Cosciente? Per Faggin è un'Illusione: Cosa Manca Davvero alle Macchine",
  "description": "Perché secondo Federico Faggin l'IA non capirà mai davvero: significato vs sintassi, intenzionalità, corpo ed esperienza. Spiegazione semplice con esempi, obiezioni e fonti 2025.",
  "inLanguage": "it-IT",

  "url": "https://messymind.it/faggin-ia-non-cosciente/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://messymind.it/faggin-ia-non-cosciente/"
  },

  "image": "https://messymind.it/assets/images/faggin-ia-cosciente.jpg",

  "author": {
    "@type": "Person",
    "name": "MessyMind"
  },
  "publisher": {
    "@type": "Organization",
    "name": "MessyMind",
    "logo": {
      "@type": "ImageObject",
      "url": "https://messymind.it/assets/logo.png",
      "width": 512,
      "height": 512
    }
  },

  "datePublished": "2025-09-08",
  "dateModified": "2025-09-08",

  "wordCount": 1200,
  "timeRequired": "PT7M",

  "isPartOf": {
    "@type": "Blog",
    "name": "MessyMind",
    "url": "https://messymind.it/"
  },

  "about": [
    { "@type": "Person", "name": "Federico Faggin" },
    { "@type": "Thing", "name": "Quantum Information Panpsychism (QIP)" },
    { "@type": "Thing", "name": "Integrated Information Theory (IIT)" },
    { "@type": "Thing", "name": "Global Workspace Theory (GWT)" },
    { "@type": "Thing", "name": "Filosofia della mente" }
  ],
  "mentions": [
    { "@type": "Organization", "name": "ANSA" },
    { "@type": "Organization", "name": "Mondadori" }
  ]
}
</script>

<!-- Schema.org: FAQPage -->
<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@type":"FAQPage",
  "mainEntity":[
    {
      "@type":"Question",
      "name":"Perché secondo Faggin l'IA non può essere cosciente?",
      "acceptedAnswer":{
        "@type":"Answer",
        "text":"Per Faggin, l'IA manipola simboli (sintassi) ma non attribuisce significati (semantica). I significati nascono solo dall'esperienza cosciente di un soggetto (seità), che un sistema computazionale, per sua natura, non possiede."
      }
    },
    {
      "@type":"Question",
      "name":"Cosa significa 'intenzionalità' nella filosofia della mente?",
      "acceptedAnswer":{
        "@type":"Answer",
        "text":"È la proprietà degli stati mentali (desideri, credenze) di essere 'diretti verso' qualcosa, di avere un contenuto. Per Faggin, l'IA simula stati intenzionali ma non li possiede realmente."
      }
    },
    {
      "@type":"Question",
      "name":"Embodiment e grounding: rendono l'IA cosciente?",
      "acceptedAnswer":{
        "@type":"Answer",
        "text":"Secondo Faggin, no. Un corpo robotico fornirebbe all'IA più dati sensoriali (simboli), ma non creerebbe un soggetto che fa esperienza di quei dati. Migliorerebbe la correlazione, non la comprensione."
      }
    },
    {
      "@type":"Question",
      "name":"Se l'IA non è cosciente, può comunque essere pericolosa?",
      "acceptedAnswer":{
        "@type":"Answer",
        "text":"Assolutamente sì. Un'IA super intelligente ma non cosciente è come un'arma autonoma e perfetta: può portare a termine il suo obiettivo in modo spietato ed efficiente, senza alcuna comprensione etica delle conseguenze."
      }
    }
  ]
}
</script>
